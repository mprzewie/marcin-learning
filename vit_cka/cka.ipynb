{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "049e1b2e-c739-49e9-bdb7-f177119e02a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import requests\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import mae\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms as T\n",
    "from cka import CudaCKA\n",
    "from collections import defaultdict\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22fcc72f-6bb0-4c92-9cdf-a133b946ba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "imagenet_std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "ds = ImageFolder(\n",
    "    \"/shared/sets/datasets/vision/IN-100/val/\",\n",
    "    transform=T.Compose([\n",
    "        T.Resize((224, 224)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(imagenet_mean, imagenet_std)\n",
    "    ])\n",
    ")\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size=5, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3071db93-60d2-4f2e-b0fc-e1053e9425b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = torch.tensor([0.5, 0.3, 0.7, 0.1, 0.2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ffc2c6d-079d-4b94-b7d8-a3cbb7c825b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3, 4, 1, 0, 2]), tensor([3, 2, 4, 0, 1]), tensor([3, 4, 1, 0, 2]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argsort(n), torch.argsort(torch.argsort(n)), torch.argsort(torch.argsort(torch.argsort(n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2730e83-5d2e-4cf6-a9bb-d4ecef7e6355",
   "metadata": {},
   "outputs": [],
   "source": [
    "cka = CudaCKA(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d248a1e7-4358-4a9a-a2c1-990400fbc99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_mae = mae.mae_vit_base_patch16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7690804f-d0db-439e-a1ad-32da2465e23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_ratio_to_cka = defaultdict(list)\n",
    "\n",
    "for (x,y) in dl:\n",
    "    \n",
    "    x = x.to(device)\n",
    "    tokens, mask, ids, x_blocks = vit_mae.forward_encoder(x, 0)\n",
    "    x_blocks_no_cls = x_blocks[:, :, 1:, :]\n",
    "    \n",
    "    x_blocks_ordered = x_blocks_no_cls.gather(\n",
    "        dim=2, \n",
    "        index=ids.unsqueeze(0).unsqueeze(-1).repeat(\n",
    "            x_blocks_no_cls.shape[0], 1, 1, x_blocks_no_cls.shape[3]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # as a sanity check, forward_encoder twice with the same mask ratio, unshuffle tokens and and obtain 100% CKA\n",
    "    \n",
    "    \n",
    "    \n",
    "    for mask_ratio in [0.0, ]: #0.1, 0.3,]: # 0.5, 0.7, 0.9]:\n",
    "        _, m_mask, m_ids, m_x_blocks = vit_mae.forward_encoder(x, mask_ratio)\n",
    "        m_ids_shuffle = torch.argsort(m_ids)\n",
    "        x_blocks_ordered_for_m = x_blocks_ordered.gather(\n",
    "            dim=2,\n",
    "            index=m_ids.unsqueeze(0).unsqueeze(-1).repeat(\n",
    "                x_blocks_ordered.shape[0], 1, 1, x_blocks_ordered.shape[3]\n",
    "            )\n",
    "        )\n",
    "        x_blocks_ordered_for_m = x_blocks_ordered_for_m[:, :, :m_x_blocks.shape[2], :]\n",
    "        \n",
    "        x_blocks_ordered_for_m = torch.cat([x_blocks[:, :, :1, :], x_blocks_ordered_for_m], dim=2) # re-add the cls token\n",
    "        \n",
    "        n_blocks, bs, nt, ts = x_blocks_ordered_for_m.shape\n",
    "        assert m_x_blocks.shape == x_blocks_ordered_for_m.shape\n",
    "            \n",
    "        for block_id in range(len(m_x_blocks)):\n",
    "            orig_tokens = x_blocks_ordered_for_m[block_id].reshape((bs*nt, ts))\n",
    "            m_tokens = m_x_blocks[block_id].reshape((bs*nt, ts))\n",
    "            \n",
    "            block_ratio_to_cka[(block_id, mask_ratio, \"linear\")].append(\n",
    "                cka.linear_CKA(orig_tokens, m_tokens) #TODO\n",
    "                # cka.linear_CKA(orig_tokens, orig_tokens) #TODO\n",
    "\n",
    "            )\n",
    "            \n",
    "        # m_x_blocks_no_cls = m_x_blocks[:, :, 1:, :]\n",
    "        # m_x_blocks_ordered = m_x_blocks_no_cls.gather(\n",
    "        #     dim=2,\n",
    "        #     index=m_ids.unsqueeze(0).unsqueeze(-1).repeat(\n",
    "        #         m_x_blocks_no_cls.shape[0], 1, 1, m_x_blocks_no_cls.shape[3]\n",
    "        #     )\n",
    "        # )\n",
    "        \n",
    "    \n",
    "    break\n",
    "    \n",
    "x.shape, x_blocks.shape, x_blocks_no_cls.shape, x_blocks_ordered.shape, x_blocks_ordered_for_m.shape, m_x_blocks.shape, block_ratio_to_cka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8db5f37-4a4d-4dc3-925b-c12c5ae40901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137.2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "196 * 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92c6aee3-19f2-4498-b90b-ac531be09db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 5, 138, 768])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_x_blocks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "948f3229-0562-475f-80f8-ee7bbcdeff1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 5, 138, 768])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_blocks_ordered_for_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab47ad4f-2742-4fe0-a6a9-da229aeea31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 0, 2, 1, 3],\n",
       "        [2, 4, 1, 0, 3]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argsort(torch.tensor([[2,4,3,5,1], [9,4,2,10,3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5e4867a-88f9-419e-b7dd-6d540d02b119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 196])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f039fe84-6be5-4f65-9bfc-39e2b054d998",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_blocks_no_cls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7be016-9fe1-4109-bada-4c94cf387f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids.unsqueeze(-1).repeat(1, 1, x_blocks_no_cls.shape[2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cfc4b1-3936-49cf-a004-93acd15a4f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bec427a-95a1-416c-842a-c9e5b527c815",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_tryout = torch.tensor([[2,0,1], [1,2,0]]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d841173-0e62-4917-bb51-0f0059069dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tryout = torch.arange(24).reshape((2,3,4))\n",
    "# batch - 2\n",
    "# n_tokens - 3\n",
    "# token_shape = 4\n",
    "x_tryout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c26d335-dd30-4811-802c-fce105c5936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_tryout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165a5da5-5363-45da-8692-0e163f18059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tryout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c54bc7-9a24-41d1-b633-1330ad8de2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids_tryout.repeat([1,1,1,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b23322d-9b73-4aea-a34b-d071bb7756ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tryout.gather(dim=1, index=ids_tryout.unsqueeze(-1).repeat(1, 1, x_tryout.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf6b128-38e1-4be2-bf1c-129478fbc456",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tryout[[0, 1], [[2,0,1]]] #[[[2, 0, 1],[1, 2, 0]] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8ee31a-c328-4136-ad43-44cf605d0114",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab1dc3b-c732-450f-8a96-1e93b1f8cbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b9df2e-8d57-442e-805b-e6930440536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack(x_blocks).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b697ff43-0355-4698-aae8-f70ffcaab3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens, mask, ids, x_blocks = vit_mae.forward_encoder(x, 0.25)\n",
    "x.shape, ids.shape, tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649cd033-cd0e-4393-adc1-2ef8bfe9fcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = vit_mae.forward_decoder(tokens, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e149e7-d7d6-4e4c-9f57-793b6b60bf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = vit_mae.patch_embed(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7753fa8b-49d7-4717-b720-b68132b8b0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = vit_mae.patchify(x)\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ba0f78-6052-437e-9774-ce53cb95e982",
   "metadata": {},
   "outputs": [],
   "source": [
    "up = vit_mae.unpatchify(p)\n",
    "up.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2408a20-99d5-4af5-b3ef-5cd2dc14747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, L = 16, 196\n",
    "noise = torch.rand(N, L, device=x.device)\n",
    "ids_shuffle = torch.argsort(noise, dim=1)\n",
    "ids_restore = torch.argsort(ids_shuffle, dim=1)\n",
    "\n",
    "ids_shuffle\n",
    "ids_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f14752e-b44b-4ea8-8381-2942dd45cfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load an image\n",
    "\n",
    "\n",
    "# img_url = 'https://user-images.githubusercontent.com/11435359/147738734-196fd92f-9260-48d5-ba7e-bf103d29364d.jpg' # fox, from ILSVRC2012_val_00046145\n",
    "# # img_url = 'https://user-images.githubusercontent.com/11435359/147743081-0428eecf-89e5-4e07-8da5-a30fd73cc0ba.jpg' # cucumber, from ILSVRC2012_val_00047851\n",
    "# img = Image.open(requests.get(img_url, stream=True).raw)\n",
    "# img = img.resize((224, 224))\n",
    "# img = np.array(img) / 255.\n",
    "\n",
    "# assert img.shape == (224, 224, 3)\n",
    "\n",
    "# # normalize by ImageNet mean and std\n",
    "# img = img - imagenet_mean\n",
    "# img = img / imagenet_std\n",
    "\n",
    "# plt.rcParams['figure.figsize'] = [5, 5]\n",
    "# show_image(torch.tensor(img))\n",
    "plt.imshow(\n",
    "    up[0].permute(1,2,0) * imagenet_std + imagenet_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d850055-f59d-4394-aed7-9a122e6228bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_mae = mae.mae_vit_base_patch16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59591fa5-04c8-4bab-a828-92e58282798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uj",
   "language": "python",
   "name": "uj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
