{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coco_stuff import COCOStuff\n",
    "from unet import UNet\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision.transforms import Normalize, ToTensor, Resize, Lambda\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = Path(\"data\")\n",
    "IMG = DATA / \"images\"\n",
    "IMG_TRAIN = IMG / \"train2017\"\n",
    "IMG_VAL = IMG / \"val2017\"\n",
    "\n",
    "ANNOT = DATA / \"annotations\"\n",
    "ANNOT_TRAIN = ANNOT / \"stuff_train2017.json\"\n",
    "ANNOT_VAL = ANNOT / \"stuff_val2017.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 256, 256 #(512, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = [\n",
    "    ToTensor(), \n",
    "    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    Lambda(\n",
    "        lambda img: F.interpolate(img.unsqueeze(0), INPUT_SIZE, mode=\"bilinear\", align_corners=True).squeeze()\n",
    "    )\n",
    "\n",
    "]\n",
    "\n",
    "mask_transforms = [\n",
    "    Lambda(lambda mask: torch.FloatTensor(np.expand_dims(mask, axis=2)).permute(2, 0, 1)),\n",
    "    Lambda(\n",
    "        lambda mask: F.interpolate(\n",
    "            mask.unsqueeze(0), INPUT_SIZE, mode=\"nearest\"\n",
    "        ).squeeze()\n",
    "    ),\n",
    "    Lambda(lambda mask: mask.squeeze().long())    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_val.coco.loadAnns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_train = COCOStuff(\n",
    "#     images_path=IMG_TRAIN,\n",
    "#     annotations_json=ANNOT_TRAIN,\n",
    "#     transformations=image_transforms,\n",
    "#     target_transformations=mask_transforms\n",
    "# )\n",
    "\n",
    "\n",
    "ds_val = COCOStuff(\n",
    "    images_path=IMG_VAL,\n",
    "    annotations_json=ANNOT_VAL,\n",
    "    transformations=image_transforms,\n",
    "    target_transformations=mask_transforms\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = ds_val.coco.loadAnns(ds_val.coco.getAnnIds(139))\n",
    "annotations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_val.n_classes, ds_val.n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_val.coco.loadCats(ds_val.coco.getCatIds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, mask = ds_val.get_image_and_mask(ds_val._image_id(4145))\n",
    "for i in np.unique(mask):\n",
    "    cat = [\n",
    "        c for c in ds_val.coco.loadCats(ds_val.coco.getCatIds())\n",
    "        if c[\"id\"] == i\n",
    "    ]\n",
    "    plt.title(cat)\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(mask==i, alpha=0.7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = DataLoader(ds_train, batch_size=4,shuffle=True)\n",
    "loader_val = DataLoader(ds_val, batch_size=2)\n",
    "iter_train = iter(loader_train)\n",
    "iter_val = iter(loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = UNet(n_classes=ds_train.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deepcopy(model_base).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "optimizer= optim.Adam(model.parameters(), lr=4e-2) #, weight_decay=10e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, mask = next(iter(loader_train))\n",
    "img = img.to(device)\n",
    "model(img).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = 1\n",
    "epochs = 1\n",
    "loss_hist = []\n",
    "acc_hist = []\n",
    "loss_val_hist = []\n",
    "acc_val_hist = []\n",
    "\n",
    "for i in range(iters):\n",
    "    model.train()\n",
    "    ls = []\n",
    "    acc = []\n",
    "    epochbar = tqdm(range(epochs))\n",
    "    for e in epochbar:\n",
    "        X_train, y_train = next(iter_train)\n",
    "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "        y_pred = model(X_train)\n",
    "        _, logits = torch.max(y_pred, 1)\n",
    "        train_loss = loss_fn(y_pred, y_train)\n",
    "        train_accuracy = (logits == y_train).sum().item() / y_train.nelement()\n",
    "        ls.append(train_loss.item())\n",
    "        acc.append(train_accuracy)        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        epochbar.set_description(\n",
    "            f\"iter: {i} | \" \n",
    "            f\"train_loss: {np.mean(ls)} | \"\n",
    "            f\"train_acc: {np.mean(acc)}\"\n",
    "        )\n",
    "    loss_hist.append(np.mean(ls))\n",
    "    acc_hist.append(np.mean(acc))\n",
    "    \n",
    "    model.eval()\n",
    "    ls = []\n",
    "    acc = []\n",
    "    for _ in range(10):\n",
    "        X_val, y_val = next(iter_val)\n",
    "        X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "        y_pred = model(X_val)\n",
    "        _, logits = torch.max(y_pred, 1)\n",
    "        val_loss = loss_fn(y_pred, y_val)\n",
    "        val_accuracy = (logits == y_val).sum().item() / y_val.nelement()\n",
    "        ls.append(val_loss.item())\n",
    "        acc.append(val_accuracy)     \n",
    "    loss_val_hist.append(np.mean(ls))\n",
    "    acc_val_hist.append(np.mean(acc))\n",
    "    print(\n",
    "            f\"val_loss: {loss_val_hist[-1]} | \"\n",
    "            f\"val_acc: {acc_val_hist[-1]}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"loss\")\n",
    "plt.plot(range(len(loss_hist)), loss_hist, label=\"train\")\n",
    "plt.plot(range(len(loss_val_hist)), loss_val_hist,label=\"val\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"accuracy\")\n",
    "plt.plot(range(len(acc_hist)), acc_hist, label=\"train\")\n",
    "plt.plot(range(len(acc_val_hist)), acc_val_hist,label=\"val\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, mask = ds_val[60]\n",
    "_, mask_pred = torch.max(model(img.unsqueeze(0).to(device)), 1)\n",
    "mask_pred = mask_pred.cpu()\n",
    "\n",
    "print(\"accuracy\", (mask.numpy() == mask_pred.numpy()).mean())\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(mask) #, alpha = 0.3)\n",
    "plt.show()\n",
    "\n",
    "# plt.imshow(img.permute(1, 2, 0))\n",
    "plt.imshow(mask_pred.squeeze()) #, alpha = 0.3)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
